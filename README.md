This project's aim is to be able to move a robotic arm using the user's thoughts and actions.

Components Used:
    - OpenBCI 16-Channel Ultracortex Headset Mark IV - https://shop.openbci.com/products/ultracortex-mark-iv

    - Cyton-Daisy Board - https://shop.openbci.com/products/cyton-daisy-biosensing-boards-16-channel

    - Brainflow Python Library - https://brainflow.readthedocs.io/en/stable/index.html

    - Arduino UNO Microprocessor - https://store-usa.arduino.cc/products/arduino-uno-rev3

    - Robotic Hand With Individual Servo Motors Per Finger - https://www.amazon.com/Fingers-Movement-Bionic-Mechanical-DIY%EF%BC%88Right/dp/B081RR4224?source=ps-sl-shoppingads-lpcontext&smid=A1K1UK7O5KP6WQ&th=1


Developed By: Rithvik Praveen Kumar (rithvikpkx@gmail.com)
